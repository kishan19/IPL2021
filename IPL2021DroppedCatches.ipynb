{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPL Dropped catches data\n",
    "\n",
    "- Match ID\n",
    "- Match name\n",
    "- Match Date\n",
    "- Ball\n",
    "- Bowler\n",
    "- Fielder\n",
    "- Batsman\n",
    "- Fielding position\n",
    "- Fielding team\n",
    "- Batting team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-02f045946b4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m    \u001b[0;34m\"ent_id_sep\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"||\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m }\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mruler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"entity_ruler\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/IPL/.ipl/lib/python3.8/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \"\"\"\n\u001b[0;32m---> 50\u001b[0;31m     return util.load_model(\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     )\n",
      "\u001b[0;32m~/Desktop/IPL/.ipl/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# from selenium import webdriver\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler\n",
    "import spacy\n",
    "config = {\n",
    "   \"phrase_matcher_attr\": None,\n",
    "   \"validate\": True,\n",
    "   \"overwrite_ents\": True,\n",
    "   \"ent_id_sep\": \"||\",\n",
    "}\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ruler=nlp.add_pipe(\"entity_ruler\", config=config)\n",
    "\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# chrome_options = Options()  \n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "# chromedriver=\"./data/chromedriver_updated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fielding_df=pd.read_excel('../Assignment/data/cricketEntities.xlsx')\n",
    "fielding_patterns=[{\"label\":\"F-POS\",\"pattern\":i} for i in fielding_df['scoring_zones'].tolist()]\n",
    "ruler.add_patterns(fielding_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/ner-elmo.2021-02-12.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overs_format(overs):\n",
    "    '''Function to adjust cricbuzz overs to cricinfo overs'''\n",
    "    try:\n",
    "        int(overs)\n",
    "        adjusted_overs=(int(overs)-1)+0.6\n",
    "    except Exception as ex:\n",
    "        adjusted_overs=overs\n",
    "    return adjusted_overs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cricbuzz_urls(cricbuzz_match_url):\n",
    "    '''Parse any cricbuzz URL'''\n",
    "    driver = webdriver.Chrome(executable_path=chromedriver,options=chrome_options)\n",
    "    driver.get(cricbuzz_match_url)\n",
    "    cricbuzz_match_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    driver.quit()\n",
    "    return cricbuzz_match_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comm_text_drop_catches(comm_text,allen_nlp_predictor):\n",
    "    '''Extract the following from Cricbuzz commentary text'''\n",
    "    '''Returns \n",
    "    - Action performer (bowler)\n",
    "    - Action receiver (batsman)\n",
    "    - Action performer (fielder)\n",
    "    - Fielding position (fielding entity)'''\n",
    "    players=[]\n",
    "    try:\n",
    "        #bowler=comm_text.split(',')[0].split('to')[0].strip().lower()\n",
    "        bowler=comm_text.split(',')[0][:comm_text.split(',')[0].find(' to ')].strip().lower()\n",
    "        #batsman=comm_text.split(',')[0].split('to')[1].strip().lower()\n",
    "        batsman=comm_text.split(',')[0][comm_text.split(',')[0].find(' to '):].replace(' to ','').strip().lower()\n",
    "    except Exception as ex:\n",
    "        bowler=''\n",
    "        batsman=''\n",
    "    \n",
    "    ##Use Allen NLP named entities to recognize fielders in play\n",
    "    ner_results=allen_nlp_predictor.predict(\n",
    "    sentence=comm_text)\n",
    "        \n",
    "    ent_dict=([(ner_results['tags'][n],word) for n,word in enumerate(ner_results['words']) if 'PER' in ner_results['tags'][n]])\n",
    "    \n",
    "    if len(ent_dict)==0:\n",
    "        fielder=''\n",
    "    else:\n",
    "        ##Handle B-PER I-PER and U-PER logic\n",
    "        players=[(ent_dict[n-1][1].lower()+' '+e[1].lower()+' '+ent_dict[n+1][1].lower()) for n,e in enumerate(ent_dict) if 'I-PER' in e[0]]\n",
    "        \n",
    "        ##Handle B-PER U-PER logic\n",
    "        p1=[(e[1].lower()+' '+ent_dict[n+1][1].lower()).strip() for n,e in enumerate(ent_dict) if 'B-PER' in e[0]]\n",
    "        b_dummy=[players.append(p) for p in p1 if p not in players]\n",
    "        \n",
    "        ##Handle U-PER logic\n",
    "        \n",
    "        p2=[e[1].lower() for n,e in enumerate(ent_dict) if ('U-PER' in e[0])&(len(list(filter(lambda x: e[1] in x, players)))==0)]\n",
    "        a_dummy=[players.append(p) for p in p2 if p not in players]\n",
    "        \n",
    "        ##Ensure no repeat of substrings\n",
    "        players=[p for n,p in enumerate(players) if len(list(filter(lambda x:p in x,players)))<=1]\n",
    "        \n",
    "        ##Adjust duplicate substrings at this stage\n",
    "        \n",
    "#     else:\n",
    "#         for n,e in enumerate(ent_dict):\n",
    "#             if 'B-PER' in e[0]:\n",
    "#                 players.append(e[1]+' '+ent_dict[n+1][1])\n",
    "\n",
    "#             if 'U-PER' in e[0]:\n",
    "#                 players.append(e[1])\n",
    "    \n",
    "        ##If no other fielder other than the bowler is present then it means fielder is the bowler\n",
    "        players=list(set(players))\n",
    "        ##Eliminate the batsman since he cannot be the fielder\n",
    "        players=[p for p in players if p not in [batsman]]\n",
    "        if (len(players)==1)&(bowler in players):\n",
    "            fielder=bowler\n",
    "        else:\n",
    "            fielder=','.join(set([p for p in players if p not in [bowler]]))\n",
    "\n",
    "\n",
    "        fielder=','.join(set([p for p in players if p not in [bowler,batsman]]))\n",
    "    \n",
    "    ##Use spacy NLP to get custom fielding positions\n",
    "    doc = nlp(comm_text)\n",
    "    fielding_positions=','.join(set([ent.text for ent in doc.ents if ent.label_=='F-POS']))\n",
    "    \n",
    "#     return pd.DataFrame({'bowler':[bowler],\n",
    "#                          'batsman':[batsman],\n",
    "#                          'fielder':[fielder],\n",
    "#                          'fielding_position':[fielding_positions]})\n",
    "\n",
    "    return dict({'bowler':[bowler],\n",
    "                         'batsman':[batsman],\n",
    "                         'fielder':[fielder],\n",
    "                         'fielding_position':[fielding_positions]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dropped_soup(cricbuzz_url,link_text=\"Dropped Catches\"):\n",
    "    '''Function to get specific highlights section of Cricbuzz using a link text'''\n",
    "    driver = webdriver.Chrome(executable_path=chromedriver,options=chrome_options)\n",
    "    driver.get(cricbuzz_url)\n",
    "    key_events_soup=[]\n",
    "    cricbuzz_soup2= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    try:\n",
    "        match_name=[h.text for h in cricbuzz_soup2.find_all('h1',{'class':'cb-nav-hdr cb-font-18 line-ht24'})][0].strip().split('-')[0].strip()\n",
    "        venue=[re.sub('\\W+',' ', c.text ) for c in cricbuzz_soup2.find_all('a',{'itemprop':'location'})][0].strip()\n",
    "    except Exception as ex:\n",
    "        match_name,venue='',''\n",
    "\n",
    "    ##Get all links that need to be clicked in web page\n",
    "    link_texts=[]\n",
    "    for cs in cricbuzz_soup2.find_all('a',{'class':'cb-nav-pill-1'}):\n",
    "        ##Most navigation bars have innings in the list\n",
    "        if ('Inns' in cs.text):\n",
    "            link_texts.append(cs.text.strip())\n",
    "\n",
    "    for l in link_texts:\n",
    "            try:\n",
    "                loadMoreButton=driver.find_element_by_link_text(l)\n",
    "                loadMoreButton.click()\n",
    "                time.sleep(3)\n",
    "                playerButton=driver.find_element_by_link_text(link_text)\n",
    "                playerButton.click()\n",
    "            except Exception as ex:\n",
    "                pass\n",
    "\n",
    "            ##Give it sufficient time to scrape the full highlights content\n",
    "            time.sleep(8)\n",
    "            soup=BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            key_events_soup.append(soup)\n",
    "\n",
    "    print (\"Full scraping of key events complete...\")\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    return match_name,venue,link_texts,key_events_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dropped_soup(innings_list,innings_soup):\n",
    "    '''Return dataframe of innings and dropped catch commentary texts'''\n",
    "    match_dropped_df=pd.DataFrame()\n",
    "    for inum, inngs in enumerate(innings_list):\n",
    "        soup=innings_soup[inum]\n",
    "        try:\n",
    "            over_number=[check_overs_format(k1.text) for k1 in soup.find_all('div',{'class':'cb-mat-mnu-wrp cb-ovr-num ng-binding ng-scope'})]\n",
    "            over_comm_text=[k2.text.strip() for k2 in soup.find_all('p',{'class':'cb-com-ln ng-binding cb-col cb-col-90'})]\n",
    "        \n",
    "        except Exception as ex:\n",
    "            over_number=[]\n",
    "            over_comm_text=[]\n",
    "            \n",
    "        inngs_drop_df=pd.DataFrame({'innings':inngs,'overs':over_number,'commentary_text':over_comm_text})\n",
    "        \n",
    "        match_dropped_df=pd.concat([inngs_drop_df,match_dropped_df])\n",
    "    \n",
    "#     if match_dropped_df.shape[0]==0:\n",
    "#         match_dropped_df=pd.DataFrame({'match_name':[match_name],'venue':[venue]})\n",
    "\n",
    "    return match_dropped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get list of cricbuzz URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricbuzz_highlights_url='https://www.cricbuzz.com/cricket-match-highlights/35657/pbks-vs-srh-14th-match-indian-premier-league-2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricbuzz_highlights_soup=parse_cricbuzz_urls(cricbuzz_highlights_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricbuzz_match_facts=cricbuzz_highlights_url.replace('cricket-match-highlights','cricket-match-facts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_name,venue,innings_list,innings_soup=get_dropped_soup(cricbuzz_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dropped_df=process_dropped_soup(innings_list,innings_soup)\n",
    "match_dropped_df['venue']=venue\n",
    "match_dropped_df['match_name']=match_name\n",
    "match_dropped_df['comm_parse']=match_dropped_df['commentary_text'].apply(lambda x:comm_text_drop_catches(x,allen_nlp_predictor))\n",
    "match_dropped_df['bowler']=match_dropped_df['comm_parse'].apply(lambda x:x['bowler'][0] if len(x['bowler'])==1 else x['bowler'])\n",
    "match_dropped_df['batsman']=match_dropped_df['comm_parse'].apply(lambda x:x['batsman'][0] if len(x['batsman'])==1 else x['batsman'])\n",
    "match_dropped_df['fielder']=match_dropped_df['comm_parse'].apply(lambda x:x['fielder'][0] if len(x['fielder'])==1 else x['fielder'])\n",
    "match_dropped_df['fielding_position']=match_dropped_df['comm_parse'].apply(lambda x:x['fielding_position'][0] if len(x['fielding_position'])==1 else x['fielding_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dropped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cricbuzz_urls(cricbuzz_match_url):\n",
    "    '''Parse any cricbuzz URL'''\n",
    "    driver = webdriver.Chrome(executable_path=chromedriver,options=chrome_options)\n",
    "    driver.get(cricbuzz_match_url)\n",
    "    cricbuzz_match_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    driver.quit()\n",
    "    return cricbuzz_match_soup\n",
    "\n",
    "cricbuzz_highlights_soup=parse_cricbuzz_urls(cricbuzz_highlights_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get fielding keeper and captain\n",
    "cricbuzz_facts_soup=parse_cricbuzz_urls(cricbuzz_match_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playing_x1_soup=[pl for pl in cricbuzz_facts_soup.find_all('div',{'class':'cb-col cb-col-27 cb-mat-fct-itm text-bold'}) if pl.text=='Playing:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playing_x1_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams=[t.strip() for t in cricbuzz_highlights_soup.find('h1',{'class':'cb-nav-hdr cb-font-18 line-ht24'}).\n",
    "       text.split(',')[0].split('vs')]\n",
    "\n",
    "teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playing_x1_dict=defaultdict(list)\n",
    "##Reversed since we are interested in identifying fielding captains and fielding keepers\n",
    "for pn,psoup in enumerate(reversed(playing_x1_soup)):\n",
    "    captain=[plr.text.split('(')[0].strip() for plr in psoup.next_element.next_element.next_element.find_all('a') if '(c)' in plr.text  or '(c & wk)' in plr.text][0]\n",
    "    keeper=[plr.text.split('(')[0].strip() for plr in psoup.next_element.next_element.next_element.find_all('a') if '(wk)' in plr.text  or '(c & wk)' in plr.text][0]\n",
    "    playing_x1_dict[teams[pn]]=[captain,keeper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innings_ck_df=pd.DataFrame()\n",
    "for k,v in dict(playing_x1_dict).items():\n",
    "    df=pd.DataFrame({k:v})\n",
    "    innings_ck_df=pd.concat([df,innings_ck_df])\n",
    "    \n",
    "innings_ck_df=innings_ck_df.melt().dropna().reset_index(drop=True)\n",
    "innings_ck_df['Role']=['Captain','WK','Captain','WK']\n",
    "innings_ck_df.columns=['Team','Player','Role']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innings_ck_df=innings_ck_df.pivot_table(index='Team',columns='Role',values='Player',aggfunc='sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innings_ck_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overs_format(overs):\n",
    "    '''Function to adjust cricbuzz overs to cricinfo overs'''\n",
    "    try:\n",
    "        int(overs)\n",
    "        adjusted_overs=(int(overs)-1)+0.6\n",
    "    except Exception as ex:\n",
    "        adjusted_overs=overs\n",
    "    return adjusted_overs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "\n",
    "allen_nlp_predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/ner-elmo.2021-02-12.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fielding_df=pd.read_excel('../Assignment/data/cricketEntities.xlsx')\n",
    "fielding_patterns=[{\"label\":\"F-POS\",\"pattern\":i} for i in fielding_df['scoring_zones'].tolist()]\n",
    "ruler.add_patterns(fielding_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comm_text_drop_catches(comm_text,allen_nlp_predictor):\n",
    "    '''Extract the following from Cricbuzz commentary text'''\n",
    "    '''Returns \n",
    "    - Action performer (bowler)\n",
    "    - Action receiver (batsman)\n",
    "    - Action performer (fielder)\n",
    "    - Fielding position (fielding entity)'''\n",
    "    players=[]\n",
    "    try:\n",
    "        #bowler=comm_text.split(',')[0].split('to')[0].strip().lower()\n",
    "        bowler=comm_text.split(',')[0][:comm_text.split(',')[0].find(' to ')].strip().lower()\n",
    "        #batsman=comm_text.split(',')[0].split('to')[1].strip().lower()\n",
    "        batsman=comm_text.split(',')[0][comm_text.split(',')[0].find(' to '):].replace(' to ','').strip().lower()\n",
    "    except Exception as ex:\n",
    "        bowler=''\n",
    "        batsman=''\n",
    "    \n",
    "    ##Use Allen NLP named entities to recognize fielders in play\n",
    "    ner_results=allen_nlp_predictor.predict(\n",
    "    sentence=comm_text)\n",
    "        \n",
    "    ent_dict=([(ner_results['tags'][n],word) for n,word in enumerate(ner_results['words']) if 'PER' in ner_results['tags'][n]])\n",
    "    \n",
    "    if len(ent_dict)==0:\n",
    "        fielder=''\n",
    "    else:\n",
    "        ##Handle B-PER I-PER and U-PER logic\n",
    "        players=[(ent_dict[n-1][1].lower()+' '+e[1].lower()+' '+ent_dict[n+1][1].lower()) for n,e in enumerate(ent_dict) if 'I-PER' in e[0]]\n",
    "        \n",
    "        ##Handle B-PER U-PER logic\n",
    "        p1=[(e[1].lower()+' '+ent_dict[n+1][1].lower()).strip() for n,e in enumerate(ent_dict) if 'B-PER' in e[0]]\n",
    "        b_dummy=[players.append(p) for p in p1 if p not in players]\n",
    "        \n",
    "        ##Handle U-PER logic\n",
    "        \n",
    "        p2=[e[1].lower() for n,e in enumerate(ent_dict) if ('U-PER' in e[0])&(len(list(filter(lambda x: e[1] in x, players)))==0)]\n",
    "        a_dummy=[players.append(p) for p in p2 if p not in players]\n",
    "        \n",
    "        ##Ensure no repeat of substrings\n",
    "        players=[p for n,p in enumerate(players) if len(list(filter(lambda x:p in x,players)))<=1]\n",
    "        \n",
    "        ##Adjust duplicate substrings at this stage\n",
    "        \n",
    "#     else:\n",
    "#         for n,e in enumerate(ent_dict):\n",
    "#             if 'B-PER' in e[0]:\n",
    "#                 players.append(e[1]+' '+ent_dict[n+1][1])\n",
    "\n",
    "#             if 'U-PER' in e[0]:\n",
    "#                 players.append(e[1])\n",
    "    \n",
    "        ##If no other fielder other than the bowler is present then it means fielder is the bowler\n",
    "        players=list(set(players))\n",
    "        ##Eliminate the batsman since he cannot be the fielder\n",
    "        players=[p for p in players if p not in [batsman]]\n",
    "        if (len(players)==1)&(bowler in players):\n",
    "            fielder=bowler\n",
    "        else:\n",
    "            fielder=','.join(set([p for p in players if p not in [bowler]]))\n",
    "\n",
    "\n",
    "        fielder=','.join(set([p for p in players if p not in [bowler,batsman]]))\n",
    "    \n",
    "    ##Use spacy NLP to get custom fielding positions\n",
    "    doc = nlp(comm_text)\n",
    "    fielding_positions=','.join(set([ent.text for ent in doc.ents if ent.label_=='F-POS']))\n",
    "    \n",
    "#     return pd.DataFrame({'bowler':[bowler],\n",
    "#                          'batsman':[batsman],\n",
    "#                          'fielder':[fielder],\n",
    "#                          'fielding_position':[fielding_positions]})\n",
    "\n",
    "    return dict({'bowler':[bowler],\n",
    "                         'batsman':[batsman],\n",
    "                         'fielder':[fielder],\n",
    "                         'fielding_position':[fielding_positions]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_text=\"Hasan Mahmud to Kjorn Ottley, 2 runs, that was in the air for a while, but it just evades Tamim Iqbal at mid-on. Kjorn Ottley got hurried due to the pace on this short ball. He went for a pull and got a top-edge as Tamim tried his best to sprint across and gets his hands to it, but couldn't\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comm_text_drop_catches(comm_text,allen_nlp_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extract match commentary text to get highlights and dropped catches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricbuzz_url='https://www.cricbuzz.com/cricket-match-highlights/32257/ind-vs-eng-2nd-test-england-tour-of-india-2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dropped_soup(cricbuzz_url,link_text=\"Dropped Catches\"):\n",
    "    '''Function to get specific highlights section of Cricbuzz using a link text'''\n",
    "    driver = webdriver.Chrome(executable_path=chromedriver,options=chrome_options)\n",
    "    driver.get(cricbuzz_url)\n",
    "    key_events_soup=[]\n",
    "    cricbuzz_soup2= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    try:\n",
    "        match_name=[h.text for h in cricbuzz_soup2.find_all('h1',{'class':'cb-nav-hdr cb-font-18 line-ht24'})][0].strip().split('-')[0].strip()\n",
    "        venue=[re.sub('\\W+',' ', c.text ) for c in cricbuzz_soup2.find_all('a',{'itemprop':'location'})][0].strip()\n",
    "    except Exception as ex:\n",
    "        match_name,venue='',''\n",
    "\n",
    "    ##Get all links that need to be clicked in web page\n",
    "    link_texts=[]\n",
    "    for cs in cricbuzz_soup2.find_all('a',{'class':'cb-nav-pill-1'}):\n",
    "        ##Most navigation bars have innings in the list\n",
    "        if ('Inns' in cs.text):\n",
    "            link_texts.append(cs.text.strip())\n",
    "\n",
    "    for l in link_texts:\n",
    "            try:\n",
    "                loadMoreButton=driver.find_element_by_link_text(l)\n",
    "                loadMoreButton.click()\n",
    "                time.sleep(3)\n",
    "                playerButton=driver.find_element_by_link_text(link_text)\n",
    "                playerButton.click()\n",
    "            except Exception as ex:\n",
    "                pass\n",
    "\n",
    "            ##Give it sufficient time to scrape the full highlights content\n",
    "            time.sleep(8)\n",
    "            soup=BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            key_events_soup.append(soup)\n",
    "\n",
    "    print (\"Full scraping of key events complete...\")\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    return match_name,venue,link_texts,key_events_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dropped_soup(innings_list,innings_soup):\n",
    "    '''Return dataframe of innings and dropped catch commentary texts'''\n",
    "    match_dropped_df=pd.DataFrame()\n",
    "    for inum, inngs in enumerate(innings_list):\n",
    "        soup=innings_soup[inum]\n",
    "        try:\n",
    "            over_number=[check_overs_format(k1.text) for k1 in soup.find_all('div',{'class':'cb-mat-mnu-wrp cb-ovr-num ng-binding ng-scope'})]\n",
    "            over_comm_text=[k2.text.strip() for k2 in soup.find_all('p',{'class':'cb-com-ln ng-binding cb-col cb-col-90'})]\n",
    "        \n",
    "        except Exception as ex:\n",
    "            over_number=[]\n",
    "            over_comm_text=[]\n",
    "            \n",
    "        inngs_drop_df=pd.DataFrame({'innings':inngs,'overs':over_number,'commentary_text':over_comm_text})\n",
    "        \n",
    "        match_dropped_df=pd.concat([inngs_drop_df,match_dropped_df])\n",
    "    \n",
    "#     if match_dropped_df.shape[0]==0:\n",
    "#         match_dropped_df=pd.DataFrame({'match_name':[match_name],'venue':[venue]})\n",
    "\n",
    "    return match_dropped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_name,venue,innings_list,innings_soup=get_dropped_soup(cricbuzz_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dropped_df=process_dropped_soup(innings_list,innings_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dropped_df['venue']=venue\n",
    "match_dropped_df['match_name']=match_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dropped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dropped_df['comm_parse']=match_dropped_df['commentary_text'].apply(lambda x:comm_text_drop_catches(x,allen_nlp_predictor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dropped_df['bowler']=match_dropped_df['comm_parse'].apply(lambda x:x['bowler'][0] if len(x['bowler'])==1 else x['bowler'])\n",
    "match_dropped_df['batsman']=match_dropped_df['comm_parse'].apply(lambda x:x['batsman'][0] if len(x['batsman'])==1 else x['batsman'])\n",
    "match_dropped_df['fielder']=match_dropped_df['comm_parse'].apply(lambda x:x['fielder'][0] if len(x['fielder'])==1 else x['fielder'])\n",
    "match_dropped_df['fielding_position']=match_dropped_df['comm_parse'].apply(lambda x:x['fielding_position'][0] if len(x['fielding_position'])==1 else x['fielding_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_dropped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_button_txt=\"Dropped Catches\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricbuzz_url='https://www.cricbuzz.com/cricket-match-highlights/35627/kkr-vs-mi-5th-match-indian-premier-league-2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cricbuzz_scorecard(cricbuzz_match_url):\n",
    "    '''Parse scorecard from Cricbuzz URL'''\n",
    "    driver = webdriver.Chrome(executable_path=chromedriver)\n",
    "    driver.get(cricbuzz_match_url)\n",
    "    cricbuzz_match_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    driver.quit()\n",
    "    return cricbuzz_match_soup\n",
    "\n",
    "cricbuzz_match_soup=parse_cricbuzz_scorecard(cricbuzz_match_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_text.split(',')[0].split('to')[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=''.join(comm_text.split(',')[1:]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_text.split(',')[0].split('to')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=chromedriver,options=chrome_options)\n",
    "#driver = webdriver.Chrome(executable_path=chromedriver)\n",
    "driver.get(cricbuzz_url)\n",
    "key_events_soup=[]\n",
    "cricbuzz_soup2= BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "##Get all links that need to be clicked in web page\n",
    "link_texts=[]\n",
    "for cs in cricbuzz_soup2.find_all('a',{'class':'cb-nav-pill-1'}):\n",
    "    if ('1st Inns' in cs.text):\n",
    "        link_texts.append(cs.text.strip())\n",
    "\n",
    "for l in link_texts:\n",
    "        try:\n",
    "            loadMoreButton=driver.find_element_by_link_text(l)\n",
    "            loadMoreButton.click()\n",
    "            time.sleep(3)\n",
    "            playerButton=driver.find_element_by_link_text(\"Dropped Catches\")\n",
    "            playerButton.click()\n",
    "        except Exception as ex:\n",
    "            pass\n",
    "        \n",
    "        ##Give it sufficient time to scrape the full highlights content\n",
    "        time.sleep(8)\n",
    "        soup=BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        key_events_soup.append(soup)\n",
    "\n",
    "print (\"Full scraping of key events complete...\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_name=[h.text for h in cricbuzz_soup2.find_all('h1',{'class':'cb-nav-hdr cb-font-18 line-ht24'})][0].strip().split('-')[0].strip()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue=[re.sub('\\W+',' ', c.text ) for c in cricbuzz_soup2.find_all('a',{'itemprop':'location'})][0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_name,venue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_number=[check_overs_format(k1.text) for k1 in key_events_soup[0].find_all('div',{'class':'cb-mat-mnu-wrp cb-ovr-num ng-binding ng-scope'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dropped_soup(link_texts,key_events_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in key_events_soup[1]:\n",
    "    try:\n",
    "    over_number=[check_overs_format(k1.text) for k1 in k.find_all('div',{'class':'cb-mat-mnu-wrp cb-ovr-num ng-binding ng-scope'})]\n",
    "    over_comm_text=[k2.text.strip() for k2 in k.find_all('p',{'class':'cb-com-ln ng-binding cb-col cb-col-90'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'innings':'PBKS 1st inns','overs':over_number,'commentary_text':over_comm_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_text=\"Unadkat to Ruturaj Gaikwad, FOUR, almost a wicket first ball! Gaikwad escapes a golden duck. Goes chasing at this away-angler, away from the body and the poke results in a thick edge. Tewatia at gully dives across, gets his fingertips but it doesn't stick. Races away past short third man who chases slugglishly and fails to prevent the boundary. What a start for Unadkat and RR!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(comm_text)\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_results=allen_nlp_predictor.predict(\n",
    "    sentence=comm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_dict=([(ner_results['tags'][n],word) for n,word in enumerate(ner_results['words']) if 'PER' in ner_results['tags'][n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Handle B-PER I-PER and U-PER logic\n",
    "players=[(ent_dict[n-1][1].lower()+' '+e[1].lower()+' '+ent_dict[n+1][1].lower()) for n,e in enumerate(ent_dict) if 'I-PER' in e[0]]\n",
    "\n",
    "##Handle B-PER U-PER logic\n",
    "p1=[(e[1]+' '+ent_dict[n+1][1]).strip() for n,e in enumerate(ent_dict) if 'B-PER' in e[0]]\n",
    "b_dummy=[players.append(p) for p in p1 if p not in players]\n",
    "\n",
    "##Handle U-PER logic\n",
    "p2=[e[1] for n,e in enumerate(ent_dict) if ('U-PER' in e[0])&(len(list(filter(lambda x: e[1] in x, players)))==0)]\n",
    "a_dummy=[players.append(p) for p in p2 if p not in players]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p for p in players if 'U-PER' in e[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batsman='van der dussen'\n",
    "bowler='Haris Rauf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##If no other fielder other than the bowler is present then it means fielder is the bowler\n",
    "players=list(set(players))\n",
    "##Eliminate the batsman since he cannot be the fielder\n",
    "players=[p for p in players if p not in [batsman]]\n",
    "if (len(players)==1)&(bowler in players):\n",
    "    fielder=bowler\n",
    "else:\n",
    "    fielder=','.join(set([p for p in players if p not in [bowler]]))\n",
    "\n",
    "\n",
    "fielder=','.join(set([p for p in players if p not in [bowler,batsman]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fielder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[(e[1]+' '+ent_dict[n+1][1]).strip() for n,e in enumerate(ent_dict) if 'B-PER' in e[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = list(filter(lambda x: 'Morris' in x, l))\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[l1 for l1 in l if 'Sakariya' in l1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Check for I-pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players=[(ent_dict[n-1][1].lower()+' '+e[1].lower()+' '+ent_dict[n+1][1].lower()) for n,e in enumerate(ent_dict) if 'I-PER' in e[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[players.append(p) for p in p1 if p not in players]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=[(e[1]+' '+ent_dict[n+1][1]).strip() for n,e in enumerate(ent_dict) if 'B-PER' in e[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players[5]='van der'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2=[e[1] for n,e in enumerate(ent_dict) if ('U-PER' in e[0])&(len(list(filter(lambda x: e[1] in x, players)))==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p for n,p in enumerate(players) if len(list(filter(lambda x:p in x,players)))<=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[players.append(p) for p in p2 if p not in players]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for n,e in enumerate(ent_dict):\n",
    "    if 'B-PER' in e[0]:\n",
    "        \n",
    "        players.append(e[1]+' '+ent_dict[n+1][1])\n",
    "        \n",
    "    if 'U-PER' in e[0]:\n",
    "        players.append(e[1])\n",
    "        set([e[1] for n,e in enumerate(ent_dict) if ('U-PER' in e[0])&(len(list(filter(lambda x: e[1] in x, l)))==0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players=list(set(players))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p for p in players if 'Sakariya' in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fielder=','.join(set([p for p in players if p not in [bowler,batsman]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowler='Russell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players=[p for p in players if p not in [batsman]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Action performer (bowler)\n",
    "##Action receiver (batsman)\n",
    "## Action performer (fielder)\n",
    "##Get fielding position (Fielding entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
